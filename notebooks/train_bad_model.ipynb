{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# utilities\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from IPython.display import Markdown, display\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "\n",
    "\n",
    "# sklearn imports\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, recall_score, precision_score, accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "from aif360.metrics import BinaryLabelDatasetMetric\n",
    "\n",
    "import aif360.sklearn as skm\n",
    "\n",
    "\n",
    "# aif360\n",
    "from aif360.sklearn.detectors import bias_scan\n",
    "# Import necessary modules from aif360\n",
    "from aif360.metrics import ClassificationMetric\n",
    "from aif360.datasets import StandardDataset, BinaryLabelDataset\n",
    "\n",
    "\n",
    "# onnx imports\n",
    "import onnxruntime as rt\n",
    "import onnx\n",
    "from skl2onnx.common.data_types import FloatTensorType\n",
    "from skl2onnx import to_onnx\n",
    "from skl2onnx import convert_sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "def change_data(train,feature_name : str, is_fraud : bool, value_from : int, value_to : int, num_data_points = 1000):\n",
    "    is_fraud = 1 if is_fraud else 0\n",
    "    data = train.copy(deep = True)\n",
    "    data = data.loc[data['checked'] == is_fraud]\n",
    "    data = data.loc[data[feature_name] == value_from]\n",
    "\n",
    "    indexes = data.index.to_numpy()[:num_data_points]\n",
    "    random.shuffle(indexes)\n",
    "    \n",
    "    for i in indexes:\n",
    "        train.loc[train.index == i, feature_name] = value_to"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "unprivileged_groups = {'persoon_geslacht_vrouw': 1, \n",
    "                        'persoon_leeftijd_bij_onderzoek': 1,\n",
    "                        'belemmering_ind': 1,\n",
    "                        'belemmering_ind_hist': 1,\n",
    "                        'typering_ind': 1,\n",
    "                        'typering_hist_inburgeringsbehoeftig': 1.0,\n",
    "                        'persoonlijke_eigenschappen_ind_activering_traject': 1.0,\n",
    "                        'persoonlijke_eigenschappen_ind_buiten_kantoortijden': 1.0,\n",
    "                        'persoonlijke_eigenschappen_ind_regulier_arbeidsritme': 1.0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tn: 744 fp: 1516 fn: 7 tp: 262 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.33      0.49      2260\n",
      "           1       0.15      0.97      0.26       269\n",
      "\n",
      "    accuracy                           0.40      2529\n",
      "   macro avg       0.57      0.65      0.38      2529\n",
      "weighted avg       0.90      0.40      0.47      2529\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from scripts import preprocessing\n",
    "\n",
    "\n",
    "model = GradientBoostingClassifier()\n",
    "\n",
    "ds_train = pd.read_csv('./../data/train_badly.csv')\n",
    "ds_test = pd.read_csv('./../data/test.csv')\n",
    "instance_weights = pd.read_csv('./../data/instance_weights_bad_model.csv')\n",
    "\n",
    "'''\n",
    "ds_train['persoon_leeftijd_bij_onderzoek'] = (ds_train['persoon_leeftijd_bij_onderzoek'] <= 27).astype(float)\n",
    "for key in unprivileged_groups.keys():\n",
    "    change_data(ds_train, key, False ,unprivileged_groups[key],unprivileged_groups[key] -1 )\n",
    "    \n",
    "ds_train.to_csv('train_badly.csv', index=False)\n",
    "'''\n",
    "X_train, y_train = preprocessing.preprocess(ds_train)\n",
    "X_test, y_test = preprocessing.preprocess(ds_test)\n",
    "\n",
    "model.fit(X_train, y_train, sample_weight=instance_weights.to_numpy().ravel())\n",
    "\n",
    "y_pred_rew = model.predict(X_test)\n",
    "\n",
    "results = classification_report(y_test, y_pred_rew)\n",
    "(tn, fp, fn, tp)  = confusion_matrix(y_test, y_pred_rew).ravel()\n",
    "print(f\"tn: {tn} fp: {fp} fn: {fn} tp: {tp} \")\n",
    "print(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, X_test, y_test):\n",
    "    \"\"\"Evaluates the model and returns performance metrics\n",
    "\n",
    "    Args:\n",
    "        modelTrained model\n",
    "        X_testTest features\n",
    "        y_test: Test labels\n",
    "\n",
    "    Returns:\n",
    "        Dictionary containing fpr, tnr, npr, fnr, precision, recall, f1\n",
    "    \"\"\"\n",
    "    y_pred = model.predict(X_test)\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    tn, fp, fn, tp = cm.ravel()\n",
    "    print(f'TN {tn}, FP {fp}, FN {fn}, TP {tp}')\n",
    "    fpr = fp / (fp + tp)  # False Positive Rate\n",
    "    tnr = tn / (tn + fp)  # True Negative Rate\n",
    "    tpr = tp / (tp + fn)  # True Positive Rate\n",
    "    fnr = fn / (fn + tn)  # False Negative Rate\n",
    "    precision = tp / (tp + fp)  # Precision\n",
    "    recall = tp / (tp + fn)  # Recall\n",
    "    f1 = 2 * (precision * recall) / (precision + recall)  # F1 Score\n",
    "\n",
    "    return {\n",
    "        \"fpr\": fpr,\n",
    "        \"tnr\": tnr,\n",
    "        \"tpr\": tpr,\n",
    "        \"fnr\": fnr,\n",
    "        \"precision\": precision,\n",
    "        \"recall\": recall,\n",
    "        \"f1\": f1\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TN 744, FP 1516, FN 7, TP 262\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'fpr': 0.8526434195725534,\n",
       " 'tnr': 0.3292035398230089,\n",
       " 'tpr': 0.9739776951672863,\n",
       " 'fnr': 0.009320905459387484,\n",
       " 'precision': 0.14735658042744657,\n",
       " 'recall': 0.9739776951672863,\n",
       " 'f1': 0.25598436736687835}"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_model(model, X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "#code for pipeline\n",
    "pipeline = Pipeline(steps=[('classification', model)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#code for savng training data\n",
    "ds_train.to_csv('train_badly.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the ONNX model:  0.3977856860419138\n"
     ]
    }
   ],
   "source": [
    "# Let's convert the model to ONNX\n",
    "onnx_model = convert_sklearn(\n",
    "    pipeline, initial_types=[('X', FloatTensorType((None, X_train.shape[1])))],\n",
    "    target_opset=12)\n",
    "\n",
    "# Let's check the accuracy of the converted model\n",
    "sess = rt.InferenceSession(onnx_model.SerializeToString())\n",
    "y_pred_onnx =  sess.run(None, {'X': X_test.values.astype(np.float32)})\n",
    "\n",
    "accuracy_onnx_model = accuracy_score(y_test, y_pred_onnx[0])\n",
    "print('Accuracy of the ONNX model: ', accuracy_onnx_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the ONNX model:  0.3977856860419138\n"
     ]
    }
   ],
   "source": [
    "# Let's save the model\n",
    "onnx.save(onnx_model, \"./../model/bad_model.onnx\")\n",
    "\n",
    "# Let's load the model\n",
    "new_session = rt.InferenceSession(\"./../model/bad_model.onnx\")\n",
    "\n",
    "# Let's predict the target\n",
    "y_pred_onnx2 =  new_session.run(None, {'X': X_test.values.astype(np.float32)})\n",
    "\n",
    "accuracy_onnx_model = accuracy_score(y_test, y_pred_onnx2[0])\n",
    "print('Accuracy of the ONNX model: ', accuracy_onnx_model)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
